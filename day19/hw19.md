# FOCS Homework 19

You may edit your answers into this file, or add a separate file in the same directory.

If you add a separate file, please include the following at the top:

```
Student Name: Gabriel Butterick [change to your name]
Check one:
[x] I completed this assignment without assistance or external resources.
[ ] I completed this assignment with assistance from ___
   and/or using these external resources: ___
```

## 0. [Not a question] Terminology

In class on Monday, we drew [**call graphs**](https://en.wikipedia.org/wiki/Call_graph) of the `fib` function, with and without memoization.

This particular kind of call graph is a **dynamic call graph**, whose nodes are function *invocations* during the execution of a program. The nodes of a **static call graph** are function *names*; arrows indicate appearances of a call in the program source text.

A dynamic call graph of a *recursive* function is also called a **recursion graph**.

## 1. Predicate Calculus – Models

Consider Table 1:

| x    | y    |
| ---- | ---- |
| a    | b    |
| b    | c    |
| a    | c    |
| c    | d    |
| d    | c    |
| c    | c    |
| b    | a    |

*Table 1*: A model for `loves(x, y)`

a. For each of the following, is Table 1 a model?  Explain briefly why or why not.

1. ∃x. ∀y. loves(x, y)  False, no one value of x loves every value of y.
2. ∃y. ∀x. loves(x, y)  True, at least c loves all values of x
3. ∀x. ∃y. loves(x, y)  True, a, b, c, and d all love at least one value of y
4. ∀y. ∃x. loves(x, y)  True, a, b, c, and d all love at least one value of x
5. ∃x. ∃y. loves(x, y)  True, at least x(a) loves y(b)
6. ∃x. ∀y. ¬loves(x, y) True, 'a' does not love all elements of 'y'
7. ∃x. ¬∀y. loves(x, y) False, all values of 'x' love at least one element of 'y'

b. Consider three models: (i) objects are a, b, c, d; `loves` is Table 1; (ii) objects are integers; `loves(x, y) ` ≝ x ≧ y; (iii) `loves(x, y)` ≝ x = y. In which of these models are these statements true:

| Statement                                | Table 1 | x ≧ y | x = y |
| ---------------------------------------- | ------- | ----- | ----- |
| ∀x, x. loves(x, x)                       |   False | True  | True  |
| ∀x, y. loves(x, y) → loves(y, x)         | True    | False | True  |
| ∀x, y, z. loves(x, y) ∧ loves(y, z) → loves(x, z) | False   | True  | True  |

c. (Optional) (Because we love graphs) Draw Table 1 as a digraph. What claims do each of the following make about a node x or y, in terms of its indegree and outdegree?

1. ∀x. loves(x, y)
2. ∀y. loves(x, y)
3. ∃x. loves(x, y)
4. ∃y. loves(x, y)

## 2. Predicate Calculus – Proofs

Given axioms:

1. ∀x. sum( x, 0, x )
2. ∀x, y, z. sum( x, y, z ) → sum( x, s(y), s(z) )
3. ∀x . product( x, 0, 0 )
4. ∀x, y, z, k. product( x, y, z ) ∧  sum( x, z, k ) → product( x, s(y), k )

Prove:

1.  ∃x. sum( x, x, s(s(0)) )
First, sum is addition of the first two arguments that results in the third argument. We know this because of axioms 1 and 2. Axiom 1 states that when some function 'sum' is performed on 0 and any number, the result is the number itself. Division by 0 can't occur, so that rules out any division as the operation. Subtracting 0 from a value would give the value back, so that stands as per axiom 1. Multiplication returns a 0 if done between a 0 and any other number, so it cannot be multiplication. Axiom 2 makes subtraction impossible, because when subtracting, you are finding the difference, which means when the subtracted number shrinks, the result grows: ie. 4-2 = 2 while 4-1 = 3. This inverse relationship is expressly denied by axiom 2 because addition of a constant to both y and z would not make subtraction hold true. The reasoning behind s() being an addition of a constant is proved later. Therefore, we know that sum() adds x and y to produce z. 


By virtue of axiom 2, whatever function 's()' applies has to be either nothing, addition, or subtraction. We know this because the axiom states itself as being true for all values of x, y, and z, so any contradiction must indicate that the axiom never applies to that situation. Assume x = 2 and y = 3. z, thereby, must equal 5. According to the axiom, this implies 2 + s(3) = s(5). This works for any addition or subtraction of a constant, but multiplication or division by a constant fails. ie. 2 + 3*2 = 5*2 is false. Since we can conclude that the function s() must be nothing, addition, or subtraction, we can prove that for some x, x + x = s(s(0)). Assume s() does nothing, x = 0, 0 + 0 = 0. Assume s() adds some constant r, if the constant is even, x = r. Otherwise, because the operation is performed twice, even if the constant is odd, it still ends up being even. This holds true in concept for subtraction as well. This leaves us with two possible outcomes depending on what s() does: adds or subtracts a constant and the statement is true, or does nothing to the value and the statement is true. Because of axiom 4, we can rule out that s() does nothing, because then axiom 4 could never be satisfied. Therefore, we can assume s() adds or subtracts some constant and we know for a fact that the initial statement is true because there are no other possibilities.

2.  ∀x. sum( 0, x, x ) [hint:  induction]
We know the sum function is the same as adding the first two inputs to create the third. Addition is order independent, and therefore has the commutative property. In other words, axiom 1 claims any number added to 0 returns that number, therefore that must be true for 0 added to any number. 
Assume this isn't true, and 0 + x does not equal x. This implies that 0 + x can equal some other number than x. Because 0 is the absence of a number, effectively null, we can simplify the equation to x = x. There is no circumstance in which this is not a true statement, therefore the statement is proved.

3.  [optional super-challenge] ∀x, y, z. sum( x, y, z ) → sum( y, x, z )

## 3. Maximum Subarray

The [maximum subarray problem](https://en.wikipedia.org/wiki/Maximum_subarray_problem) (*aka* maximum contiguous subsequence, *aka* maximum value contiguous subsequence) is “the task of finding the contiguous subarray within a one-dimensional array of numbers which has the largest sum. For example, for the sequence of values −2, 1, −3, 4, −1, 2, 1, −5, 4; the contiguous subarray with the largest sum is 4, −1, 2, 1, with sum 6” ([Wikipedia](https://en.wikipedia.org/wiki/)).

```python
# Source: wikipedia 
def max_subarray(xs):
    max_ending_here = max_so_far = 0
    for x in xs:
        max_ending_here = max(0, max_ending_here + x)
        max_so_far = max(max_so_far, max_ending_here)
    return max_so_far
```

a. Draw a recursion graph of `max_subarray([−2, 1, −3, 4, −1, 2, 1, −5, 4])`.
I don't actually know what a recursion graph is, and the internet doesn't have any information on what it is, so I'm going with my best guess and assuming it depicts any recursive thing in a function. As there is no recursive thing max_subarray, I will show how the program moves through the input.
Max(0,-2)
Max(0,0)
Max(0,1)
Max(0,1)
Max(0,-2)
Max(1,0)
Max(0,5)
Max(1,5)
Max(0,4)
Max(5,4)
Max(0,6)
Max(5,6)
Max(0,1)
Max(6,1)
Max(0,5)
Max(6,5)

The program begins with setting max and so_far to 0, then iterates through the input. It then compares -2 and 0 and takes the max, which is 0, effectively removing -2 from the list of possibile parts of the result. Moving to 1, 1 is higher than 0, so that is set as the max_ending_here and the max_so_far. -3 is next, making max_ending_here 0 again and max_so_far still 1. 4 becomes max_ending_here and max_so_far, -1 makes max_ending_here 3, max_so_far still 4. 2 and 1 each add to the total, making the new max_so_far 6. -5 doesnt raise the max_so_far and the following 1 isn't enough to recover the lost ground, so the max of 6 is returned.

b. Is `max_subarray` an example of divide and conquer? Why or why not?
It simplifies the process into a series of 2 number additions, which is in the spirit of divide and conquer, but it lacks any recursion at all. As recursion is a requirement for divide and conquer, this algorithm does not fit it.

c. Is `max_subarray` an example of dynamic programming? Why or why not?
Though this code does solve easier problems just once, it doesn't appear to store all of them. This code gets the required use out of the operations, but if specific calculations were to need to be done multiple times, they would have to be redone. ie. 1,2,1,2. This code would not already have an answer for what 1+2 was, and would effectively solve it again. Therefore, it is not dynamic programming.

d. Consider a *memoized* version of `max_subarray`. (You don't need to produce code for this. You do need to understand what memoization does to a call graph.) Draw the recursion graph for `memoized_max_subarray([−2, 1, −3, 4, −1, 2, 1, −5, 4])`.
Max(0,-2)
Max(0,0)
Max(0,1)
Max(1,0)
Max(0,5)
Max(1,5)
Max(0,4)
Max(5,4)
Max(0,6)
Max(5,6)
Max(6,1)
Max(6,5)

There are slightly fewer function calls.

e. [Optional challenge] Produce working code for memoized `max_subarray`.

## 4. Binary Search

```python
def binary_search_array_helper(x, xs, left, right):
    if left == right: return None
    middle = int((left + right) / 2)
    if x < xs[middle]:
        return binary_search_array_helper(x, xs, left, middle)
    elif xs[middle] < x:
        return binary_search_array_helper(x, xs, middle, right)
    else:
        return middle

def binary_search_array(x, xs):
    return binary_search_array_helper(x, xs, 0, len(xs))
```

a. Above is an implementation of the [binary search algorithm](https://en.wikipedia.org/wiki/Binary_search_algorithm). Draw the recursion graph for `binary_search_array(3, [1, 3, 4, 6, 7, 8, 10, 13, 14]))`.

binary_search_array(3, [1, 3, 4, 6, 7, 8, 10, 13, 14]))
bsah(3,[1, 3, 4, 6, 7, 8, 10, 13, 14],0,9)
bsah(3,[1, 3, 4, 6, 7, 8, 10, 13, 14],0,4)
bsah(3,[1, 3, 4, 6, 7, 8, 10, 13, 14],2,4)


b. Is `binary_search_array` an example of divide and conquer? Why or why not?
It is, because it recursively breaks down a complex problem into a series of simpler problems.

c. Is `binary_search_array` an example of dynamic programming? Why or why not?
It is not, because it doesn't store the results of any of the smaller problems it solves.

d. Consider a memoized version of `binary_binary_search_array_helper`. Draw the recursion graph for a function memoized `memoized_binary_search_array(3, [1, 3, 4, 6, 7, 8, 10, 13, 14]))` that calls `memoized_binary_search_array_helper`.
Because there are no repeated opperations in this particular call, so the graph remains the same. Nothing that's stored would be used again to speed up computation.

binary_search_array(3, [1, 3, 4, 6, 7, 8, 10, 13, 14]))
bsah(3,[1, 3, 4, 6, 7, 8, 10, 13, 14],0,9)
bsah(3,[1, 3, 4, 6, 7, 8, 10, 13, 14],0,4)
bsah(3,[1, 3, 4, 6, 7, 8, 10, 13, 14],2,4)

e. Under what circumstances does the `memoized_binary_search_array` present any benefits over the unmemoized original? How does this relate to (i) its recursion graph; (ii) the key attributes of a dynamic program?
It presents the benefit that, if the desired element is near one that has been found before, there are far fewer necessary recursions and far less computation involved. Additionally, finding the same value multiple times would be trivial. 
i) Its recursion graph would, in the case of finding the same thing twice, be as small as calling the helper function once. If finding, for instance, a 2 in the same array as described above, most of the computation would already have been done, leaving just 2 calls instead of the original 3. Overall, it would simplify the graph in cases when redundancy was possible.
ii)This would also mean it saved the results of computationally expensive processes, meaning it would qualify as dynamic programming.

f. [Optional challenge] Find the bug in `binary_search_array`. What input will cause it to fail? How can this be fixed? (Hint: it is a bug that appears for small arrays. Python is not susceptible to [this bug](https://research.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.html).)

## 5. Datalog Tutorial

Dust off your DrRacket, and follow the Datalog tutorial [here](https://docs.racket-lang.org/datalog/Tutorial.html).

## 6. SQL

Install [SQLite](https://www.sqlite.org):

* **Linux**: `sudo apt-get install sqlite`
* **macOS** (w/ [homebrew](http://brew.sh)): `brew install sqlite3`
* **Windows**; **macOS** (w/out homebrew): download the pre-compiled binary from the [SQLite Download Page](https://sqlite.org/download.html)

Kick its tires:

```
$ sqlite3
SQLite version 3.13.0 2016-05-18 10:57:30
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database.
sqlite> create table course(title string, number string, area string, credits int);
sqlite> insert into course values ("FOCS", "ENGR3520", "ENGR", 4);
sqlite> insert into course values ("SoftDes", "ENGR2510", "ENGR", 4);
sqlite> insert into course values ("Discrete", "MTH2110", "MTH", 4);
sqlite> .mode column
sqlite> .headers on
sqlite> select * from course;
title       number      area        credits
----------  ----------  ----------  ----------
FOCS        ENGR3520    ENGR        4
SoftDes     ENGR2510    ENGR        4
Discrete    MTH2110     MTH         4
sqlite> select * from course where area="ENGR";
title       number      area        credits
----------  ----------  ----------  ----------
FOCS        ENGR3520    ENGR        4
SoftDes     ENGR2510    ENGR        4
sqlite> .quit
```

